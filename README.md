# ğŸ‘‹ Hi, Iâ€™m Vinay Kumar Chandra

ğŸš€ **Data Engineer | Cloud & AI Data Platforms | Real-Time & Scalable Systems**

I design and build **high-performance, scalable data platforms** that power analytics, machine learning, and AI-driven products. My work sits at the intersection of **data engineering, cloud architecture, and AI infrastructure**, with a strong focus on scalability, reliability, security, and business impact.

---

## ğŸ§  About Me

I am a **Data Engineer with 3+ years of industry experience**, currently working at **HubSpot**, where I help build the data backbone for AI-powered CRM products. My role focuses on designing **low-latency streaming systems**, **cloud-native data pipelines**, and **secure data access layers** that enable real-time, context-aware AI agents.

At HubSpot, Iâ€™ve contributed to:
- Real-time data ingestion and retrieval systems enabling **sub-200ms access** to tens of millions of CRM records  
- Scalable **streaming and batch pipelines** using Kafka, AWS, and Snowflake  
- Python-based parsers that convert **unstructured sales transcripts and emails** into ML-ready datasets  
- Snowflake compute optimization, significantly reducing cloud costs while supporting AI workloads  
- **Role-based access controls** to ensure GDPR-compliant handling of sensitive customer data  

Previously, I worked at **Genpact** and **Wipro**, where I built robust ELT pipelines, optimized SQL-based analytics workflows, and supported enterprise-scale data platforms. Across roles, I consistently translated ambiguous business requirements into **reliable, production-grade data solutions**.

I also hold a **Masterâ€™s degree in Applied Data Science (GPA: 4.0)**, where I gained deep hands-on experience with **big data systems, machine learning, NLP, and advanced analytics**.

---

## ğŸ—ï¸ Professional Experience Highlights

### ğŸ’¼ Data Engineer â€” HubSpot
- Engineered real-time data retrieval layers enabling AI agents to access large-scale CRM data with ultra-low latency  
- Built scalable Kafka-based streaming pipelines and Snowflake ELT workflows  
- Developed Python data parsers for unstructured text ingestion and ML preprocessing  
- Optimized Snowflake compute strategies for high-volume AI workloads  
- Implemented secure access controls for sensitive customer and PII data  

### ğŸ’¼ Data Engineer â€” Genpact
- Built and maintained ELT pipelines for analytics and reporting  
- Optimized complex SQL queries and data models for performance  
- Collaborated with cross-functional teams to deliver business-aligned data solutions  

### ğŸ’¼ Data Engineer â€” Wipro
- Supported enterprise data platforms with ingestion, transformation, and reporting workflows  
- Automated reporting and data quality checks  
- Assisted in modernizing legacy data systems  

---

## ğŸ§° Tech Stack & Skills

### ğŸ”¹ Programming Languages
- **Python**, **SQL**, R  
- Java, C++, JavaScript  

### ğŸ”¹ Cloud & Data Platforms
- **AWS** (S3, Lambda, Glue, EMR, Redshift, Athena)  
- **Snowflake**  
- **Apache Kafka**  
- **Apache Spark / PySpark**  

### ğŸ”¹ Data Engineering
- ETL / ELT Pipeline Design  
- Streaming & Batch Processing  
- Data Lakes & Lakehouse Architectures  
- Data Modeling (Star & Snowflake Schemas)  
- Performance Tuning & Cost Optimization  

### ğŸ”¹ AI / ML Data Systems
- ML & AI-ready data pipelines  
- NLP preprocessing & embeddings  
- Vector database integrations  
- Data preparation for model training & inference  

### ğŸ”¹ Tools & Ecosystem
- Docker & Docker Compose  
- dbt  
- Git & GitHub  
- Tableau, Power BI  
- Linux, Bash  

---

## ğŸ“‚ Featured Projects

### ğŸ”¹ Product Analysis & Consumer Insights Through Reviews
- Processed and analyzed Amazon appliance reviews using **BERT embeddings**  
- Clustered reviews into product subcategories using **K-Means**  
- Visualized embeddings using **UMAP, t-SNE, and PCA**  
- Generated sentiment-driven summaries using GPT-based labeling  
- Delivered actionable insights for product and consumer analysis  

### ğŸ”¹ Scalable Data Platforms & Pipelines
- Designed real-time streaming pipelines using Kafka  
- Built cloud-native ELT workflows on Snowflake  
- Implemented governance and access controls for sensitive data  
- Optimized pipelines for performance, reliability, and cost  

### ğŸ”¹ Big Data & Cloud Engineering Projects
- Distributed processing with Spark on large-scale datasets  
- End-to-end AWS data pipelines using serverless and managed services  
- Dockerized multi-service data ecosystems for experimentation  

*(Each repository includes detailed documentation, architecture diagrams, and reproducible workflows.)*

---

## ğŸ“œ Certifications

- ğŸ… AWS Certified Data Engineer â€“ Associate  
- ğŸ… AWS AI Practitioner  
- ğŸ… IBM Machine Learning with Python  

---

## ğŸ¯ Areas of Interest

- Scalable data platforms for AI & ML  
- Real-time analytics & streaming systems  
- Cloud-native data architectures  
- Data engineering for LLMs and AI agents  
- Cost-efficient, production-grade data systems  

---

## ğŸ¤ Letâ€™s Connect

ğŸ“Œ Open to conversations around **Data Engineering, AI Platforms, and Cloud Systems**

- ğŸ’¼ **LinkedIn:** [Vinay Kumar Chandra](https://www.linkedin.com/in/-vinaykumar2701/)
- ğŸ“§ **Email:** vinaykumarr2100@gmail.com  

---

â­ï¸ *If you find my work helpful, feel free to star â­ my repositories or reach out for collaboration!*
